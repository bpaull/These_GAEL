# Introduction {#intro1}

In this thesis, we try to provide elements to test temptation models in the 
laboratory. 
By temptation model we mean here the model proposed in @gul2001temptation and 
the models inspired by it, like @noor2010uphill or @noor2015menu.
Specifically, we are interested in models with the following two characteristics: 
They model preferences for menus, that is, preferences for sets of choices in 
which only one alternative can be chosen.[^101]

[^101]: More technicaly menus are subset of the set $\Delta$ endow with the weak 
topology. 
Where $\Delta$ is the set of all measures on the Borel $\sigma$-algebra of $Z$ a 
compact metric space $(Z,d)$ of all prizes.

This approach was initiated by @kreps1979representation. 
And this models must allow preference for the restrictions, that is to say that 
an individual can prefer a menu to a menu which is his super set 
(i.e to prefer a menu containing less elements).

We are interested in this model because it allows us to rationalize behavior
that cannot be rationalized within expected utility theory. 
For example, the demand for a costly commitment [@bryan2010commitment; @ashraf2006tying], the exercise of self-control [@dellavigna2004contract] or the choice of subscriptions inconsistent with the use of a service [@dellavigna2006paying]. 
We chose to focus on the temptation model from an experimental point of view 
because the theoretical literature already proposes a large number of models 
(the reader who wants to be convinced can consult the literature review on the subject @lipman2013temptation), but the experimental literature on the subject does not propose a design allowing to compare these models;
Both in terms of their descriptive and predictive performance and in terms of their accuracy in describing behavioral frequencies such as the exercise of self-control or the willingness to pay for a commitment.
The experimental literature on temptation is focused on the demonstration of existence of 
behavior predicted by theoretical models of temptation and in contradiction with 
the expected utility model. 
To mention only a few of these works, the exercise of self-control and the costs 
it induces first by @mischel1989delay and then in @kuhn2014self, the preference for a 
restricted set of choices in @toussaert2018eliciting and the demand for an expensive 
commitment in @houser2018temptation. 
This leaves room for an experimental design that would allow us to measure the 
effects of temptation on preferences and thus differentiate the different 
temptation models.
I therefore propose an experiment to test the descriptive capacity of different 
temptation models.

This thesis is composed of three chapters, each describing an online experiment. 
The first two experiments aim at testing temptation models, the first one 
focusing on a behavioral aspect through the effect of commitment on risk taking. 
The second one tests the descriptive capacity of temptation models by eliciting 
preferences for menus. 
The last one does not test temptation but the stability of preferences for money. 
The latter highlights that the instability of individual preferences has 
important consequences on the tools used in experimental economics to test a 
theory and on the reliability of the preferences elicited.

The original title of this thesis was "Temptation and strategic interaction: 
theory and experiment". 
The objective was to propose an extension to the existing temptation model, 
notably those of @gul2001temptation and @fudenberg2006dual, to take into account the combined effects of temptation and strategic interactions. 
The original PhD thesis project was based on work carried out for my master thesis. 
My master thesis consisted in a model that adapted the @fudenberg2006dual model for two individuals, each composed of two selves and having to decide on the distribution of a budget where their choice 
are strategic substitute. 
The model developed for the master thesis highlighted that with strategic substitute choice, the 
individual with the lowest self-control costs must compensate for the lack of 
self-control of the other individual. 

My first original work within the scope of this original plan was to propose an experiment to test the 
behavioral predictions of the model developed in my master's thesis. 
For that I realized a small experiment (40 subjects) built on the experimental design used by @houser2018temptation. 
In this first experiment we tested the self-control capacity of the subjects by asking 
them to perform a boring, paid task (looking at a screen displaying the current time) and giving them the possibility to switch to a more interesting, but unpaid task (surfing the 
internet). 
The subjects were also given the opportunity to costly commit: they could give up a small part of their earnings to continue the boring task without being offered the choice of switching task. 
My experimental design consisted of two parts. 
The first part was a replication of the @houser2018temptation experiment and aimed at estimating the individual self-control capacity of the subjects. 
The second part aimed at testing their self-control capacity in a context with strategic interactions. 
For this purpose, the remuneration of the daunting task was modified to place 
pairs of subjects in a situation where their choice are strategic substitute. 
The -- ex-ante unexpected -- results of this experiment are that all of our subjects chose to keep performing the 
boring task during the 2 hours of our experiment. 
This did not replicate the results of @houser2018temptation  who found that 
28.7% of the subjects keep performing the tasks without paying to avoid 
temptations and, crucially, did not allow us to test the influence of strategic 
interactions.
The differences in results with @houser2018temptation can be explained by the 
differences in dates between the 2 experiments, the original experiment having 
taken place in the early 2010s and mine in late 2018. 
The relationship to the internet has strongly evolved between these two dates 
(think of the actual use of smartphone for example)
and makes an activity like surfing the internet in a lab much less attractive. 
This first experiment taught me two lessons that were then applied in the 
remainder of the thesis.
First,  the choice of the 
tempting alternative is difficult because its tempting nature can vary between 
individuals but also over time. 
making direct replications of past successful design far from trivial.
Second, to test the impact of strategic interactions it would be easier to have 
an experimental protocol that does not rely on binary choices but allows for 
greater variability in individual behavior.

I therefore started to work on an experimental design, which would give rise to 
[chapter 3](#tempting-lab), 
that would allow the measure the effect of temptation at the 
individual level and which does not depend on the *a priori* level of temptation generated by an 
alternative but which allows us to identify which are the alternatives that the 
subject considers tempting. 
In order to do this, I chose to construct the experimental design in such a way 
as to be as close as possible to the theoretical framework proposed by 
@gul2001temptation. 
This allow to directly elicit individual preferences for menus, and to build the 
menus in such a way as that they induce different level of the temptation 
according to different theory. 

In parallel to the preparation of this protocol, Rustam Romaniuc and Dimitri 
Dubois offered me through Paolo Crosetto the opportunity to propose a treatment 
concerning temptation in their experimental project on risk. 
Their project planned to measure risk preferences repeatedly before and after an 
intervention. 
I proposed to test the impact of a freely chosen limit on the maximum level of 
risk a player could take. 
The intervention consisted in proposing to the subjects to limit the level of 
risk they could take in the second half of the experiment and to let them choose 
this level. 
But with the particularity that this limit would only be applied to a quarter of 
the people who would ask for it. 
This allows us to observe the limit that subjects desire as well as their 
behavior when this limit is not applied. 
This allows us to relate the level of the requested limit to the capacity for 
self-limitation, from our point of view the link between demand for commitment 
and capacity for self-control. 
This treatment also allows us to compare the impact of the limit when it is 
binding or not.

While analyzing the data from this experiment I noticed an unexpected 
difficulty. 
I had five observations of risk preferences for each of my subjects before and 
five after the treatment, but these five observations seemed to be extremely variable. 
This variability between the individual observations was also found in the 
observations of the subjects of our control group, who was not exposed to any treatment. 
However, if there are many experiments which inform us about the average level 
of preference for the subject (for example the @lejuez2002evaluation or 
@crosetto2013bomb to quote only the ones which inspired chapter 3), there is to 
our knowledge no article concerning the individual variability of the 
measurement of preferences for risk.
Their is works like @ert2017revisiting that make multiple measure but don't 
compute variability or like @wilcox2007predicting that compute estimation 
error but no one to the best of my knowledge compute individual variability.
Individual variability is necessary to judge the quality of the estimates, as 
well as to use simulations to calibrate the experiments and to judge the 
reliability of the experimental results.
I have therefore realized an experiment to test the variability of risk 
preferences which is described in the [fourth chapter](#multi-choice) of this thesis. 
This experiment shows that the variability of individual preferences is 
large and must be taken into account in the analysis of experimental 
results in the domain of risk attitudes
, on the one hand by having as often as possible a 
difference-in-difference analysis as other analysis design causes an 
underestimation of the risk of the first type, and on the other hand by 
recurring as little as possible to individual level estimations.
Finally, in order to take into account the results of chapter 3 I opted for a 
difference-in-difference analysis for the first chapter using a Bayesian rather 
than a frequentist approach for the estimates to account for individual 
variability. 
For chapter two I chose to modify the analysis to test the validity of the 
temptation models against statistical models in order to have a reference point.


As during these three years of thesis my work deviated from the initial subject, 
I chose to rename my thesis *Two Different Experimental Approches For Testing 
Temptation And A Test Of Stability Of Individual Risk Preferences* 
Indeed, the central point of this thesis  is to explore experimental methods to 
test temptation. 
The last two chapters are attempts to answer technical problems on the subject. 
Therefore the approach chosen throughout the thesis is somewhat different from 
the usual approach in experimental economics. 
I have chosen to use methods inspired by statistics and machine learning; 
notably the use as much as possible of training and test samples to control for 
overlearning of the models, the use of bootstrap sampling to compare results 
over a large number of samples and smooth the results, and comparisons of the 
results of our models with reference models in terms of metrics such as Mean 
Square Error (MSE). 
The use of these methods aimed at focusing our analysis on errors due to our 
observation methods, as well as those of the subjects and model errors that are 
rarely taken into account in economics as highlighted in @taleb2005fooled. 
This error-centered approach has two objectives, on the one hand to test the 
reliability of the models we are studying and the contribution of the 
experimental protocols proposed through this thesis. 
On the other hand, it allows us to approach the models we study with a 
refutation objective inspired by @popper2005logic and @popper2014conjectures. 
We compare here the models with dummy models and we show that these dummy models 
are better descriptors of individual behaviors. 
Of course this method is far from allowing a formal refutation of the models, but it is the 
closest method to refutation that I could propose.
The disadvantage of this approach is that it implies focusing on models chosen 
specifically in advance and constructing the experiment in such a way as to have 
a training set as well as a test set for the model. 
The approach chosen as well as the initial objective of answering a technical 
problem such as measuring temptation places me in a situation where the links 
with the existing literature are limited. This is particularly true with regard to chapter 
three, which deals with a question that to best of my knowledge has not been directly studied.

Even if this thesis raises more problems than it answers, I think it brings the 
following elements:

1. The first chapter provides new information on the differences between hard 
and soft commitment. 
It allows to put forward a form of complementarity between these two forms of 
commitment. 
This chapter also highlights the way in which subjects choose to use their 
self-control by allowing themselves to exceed their limit at times but by 
reducing their risk-taking below this limit at other times.
2. The second chapter shows that taking into account the effect of temptation 
marginally improves the standard model but that these models are not better 
descriptors of subjects' choices on menus than a constant choice model.
3. The third chapter highlights that individual choices in the risk domain are 
very variable to such an extent that it does not seem to be described correctly 
by a distribution with a central moment. 
This puts into question both the expected utility model and most random models 
such as @gul2006random, @ratcliff2008diffusion or @cerreia2019deliberately. 
This chapter also highlights a ghost treatment effect, finding significant 
differences between similar groups.


Finally, while this thesis does not propose an experimental protocol for 
measuring temptation, it does highlight problems in temptation models as well as 
in the expected utility model that invite us to further explore the variability 
of individual preferences.
