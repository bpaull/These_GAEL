[["tempting-lab.html", "Chapter 3 Descriptive Power of Tempting Model 3.1 Introduction 3.2 Materials and methods 3.3 Results 3.4 Discussion", " Chapter 3 Descriptive Power of Tempting Model 3.1 Introduction In this chapter we present an experiment which aims to test the descriptive capacity of the model proposed by Gul and Pesendorfer (2001) (hereafter G-P). The predictions of this model are compared with those of different economic models and with simple statistical models. To evaluate the descriptive capacity of the models, our experiment places subjects in a situation as close as possible to the theoretical framework of G-P. Subjects are asked to choose by means of an incentivized elicitation mechanism among menus composed by lotteries. A menu here is a set of 1 to 6 lotteries, from which the subject knows that she will have to choose only one lottery in the end. Our approach differs from that of the previous chapter and from experiments such as those of Houser et al. (2018) or Toussaert (2018) on the subject. Our experiment does not aim at showing the existence of a particular behavior predicted by the theory such as the demand for commitment or the capacity of the subjects to exercise their self-control. It aims instead to evaluate the ability of G-P to describe the actual behavior of the subjects, and to compare its performance to various alternatives, ranging from economic to statistical models. This experiment does not question the existence of behavior at odds with expected utility theory (hereafter EUT), such as the demand for constraints (Chow and Acland (2011), Giné, Karlan, and Zinman (2010) and Uhl and others (2011)), self-control effects (Burger, Charness, and Lynham (2011), Mischel, Shoda, and Rodriguez (1989) and Kuhn, Kuhn, and Villeval (2014)) or more surprising attitudes like those observed in DellaVigna and Malmendier (2006). These behaviors are well established in the experimental literature. Our experiment questions the menu preference approach as a way to rationalize these behaviors. This approach, initiated by Kreps (1979), aims at rationalizing the preference that individuals may have for larger sets of choices. The idea being that an individual who is uncertain about his future preferences would prefer to have a larger number of options to choose from when making his decision in order to maximize his utility. Later G-P proposed a model in which individuals may be averse to the presence of certain options and therefore prefer smaller choice sets. G-P’s model rationalizes the demand for constraints by subjects while allowing for the possibility of costly self-constraint. The G-P model was later extended to rationalize more behaviors. For example Gul and Pesendorfer (2004) for repeated choices , Noor and Takeoka (2010) for anticipated temptation cost or Noor and Takeoka (2015) for more complex interactions among elements of a menu – for a review of application and extensions of the original G-P model see the review by Lipman, Pesendorfer, and others (2013). Our experiment shows that in terms of descriptive power the G-P model is a slight improvement over EUT. But the G-P model does not do better than a dummy model where subjects all evaluate their menus in the same way and independently of their composition. Moreover, a simple regression model outperforms the G-P model. The goal of our design is to be as close as possible to the theoretical framework formulated by G-P. We have therefore focused on the elicitation of the value of menus. Unfortunately this design does not allow us to to identify the different states of the world that are at the basis of the temptation models proposed by Dekel, Lipman, and Rustichini (2001), Dekel et al. (2007) or Dekel, Lipman, and Rustichini (2009). Nor can we identify the choices of different selves as in the multiple-self models proposed by Fudenberg and Levine (2006). Therefore, we will not propose any interpretation of our data in the framework of these models. Our approach will allow us to propose a method to elicit the two functions used in the G-P model for each of our subjects. G-P shows that an individual whose preferences are complete, transitive, continuous, independent and satisfying the axiom of Set Betweenness: \\[ A \\succsim B \\text{ implies } A \\succsim A\\cup B \\succsim B \\] has a utility function for menus of the form: \\[ U(A) = max_{x \\in A}(u(x) + v(x)) - max_{y \\in A}(v(y)) \\] Where \\(A\\) and \\(B\\) are menus and \\(u(.)\\) and \\(v(.)\\) Von-Neumann Morgenstren utility functions. With \\(u(.)\\) representing the utility for the elements taken independently (singletons) and \\(v(.)\\) the temptation utility of the elements. What we will do in our analysis is to estimate for each menu the value associated for the function \\(u(.)\\) and for the function \\(v(.)\\) and to compare the theoretical value of the resulting menu to the one indicated by the subject. We do not test the validity of the axioms but that of their theoretical consequence i.e. the values predicted by the utility function corresponding to these axioms. 3.2 Materials and methods 3.2.1 Experimental design Our experiment took place online from 12/06/2020 to 19/08/2020. The recruitment of the subjects was done via the Amazon Mechanical Turk (AMT) platform. On the AMT platform a job offer was published indicating the approximate duration and the fixed payment as well as an average bonus higher than 5$. From this offer, subjects could accept to participate in our experiment by accepting the task on AMT. No selection criteria were applied a priori to the subjects. But only the subjects having filled in a valid end-of-experiment code were included in the analysis. Conditions of minimum duration of working time and number of trials were also applied but do not exclude any subject.1 The software was developed using the R language and the Shiny framework. Once the experiment is completed, the experimental software displays a summary of the subjects’ bonus and a unique code to be filled in the corresponding field on the AMT platform. This code allows us to uniquely identify the subjects’ responses between our software and the AMT platform. The target number of subjects was 300. 304 subjects filled in a response code on the AMT page but this code was only valid for 297 of them. The 7 subjects whose code was not valid were excluded from the dataset and were not paid. The experiment proceeds as follows: The subject faces a screen with instructions. This screen describes the next steps in the experiment and details how the subject will earn his payoff. The subject is given a description of the menu and how the lottery works. Particular emphasis is put on the impact on the bonus of the mechanism of choice of a menu. Instructions are provided in Appendix B. The subject has to answer a short series of multiple-choice control questions. To continue, the subject must answer all questions correctly. To do so, he has as many attempts as he wants and a help is displayed for the questions to which the answer is wrong at the first attempt. Start of incentivized learning phase: The subject has to bid on 10 pairs of menus by indicating with a slider the maximum amount he is willing to pay between -1$ and 1$ (the bidding mechanism is described in detail in the following section). The menus on which the subject bids are built in the same way as those of the rest of the experiment but the values used for the lotteries that compose them are different. One of the bids that has just been made is drawn and the subject chooses one of the lotteries that it contains. A screen indicates to the subject what amount he has won with the steps 4 and 5, either the amount resulting from the selected auction and the amount corresponding to the resolution of the chosen lottery. The subject is asked to complete a second set of control questions similar to the one in step 2 but with different questions. Main task: the subject bids on 35 comparisons between 2 menus. 5 of these comparisons are drawn at random and the subject can choose one lottery from each of the five menus assigned to him according to his bid and the elicitation mechanism. The lotteries are solved and the subject’s bonus is calculated as the total won on the 5 bids on the selected comparisons and the results of the 5 chosen lotteries plus what was already won in the learning phase. On the final page, a table summarizes the subject’s winnings by selected comparisons indicating the amount won via the auction and the lottery results. The total of the 6 auctions and lotteries is also displayed along with a reminder that the subject must fill in the code displayed on this page on AMT. Our experiment is composed of only one treatment. The earnings of the subjects are paid via the AMT platform. They are composed of a fixed part of 1$ paid to all the subjects who filled in a valid code in the AMT form, and a variable part calculated according to the bids on the 6 selected comparisons and the resolution of the 6 lotteries they chose (1 in the learning and 5 in the main phase). Our subjects were thus paid an average of 6.97$ for an average time of 41 minutes spent on our experiment. So an average wage per hour of 10.3$ The objective of our experimental protocol is to elicit the value that subjects place on menus. A menu is a set of items from which the subject must choose 1 and only 1 item. To be as close as possible to the theoretical model of G-P we chose to build our menus with lotteries. In order to keep our experiment as simple as possible we chose to use binary lotteries similar to the bets that can be made in roulette games in casinos. That is to say lotteries allowing to win \\(n\\)$ with a probability of \\(\\frac{1}{n}\\) and 0$ otherwise. The menus can be composed of 1 to 6 lotteries with the possible values of \\(n \\in \\{2, 4, 6, 8, 16, 32\\}\\). All lotteries have the same expected value of 1, and differ in variance only, that is increasing in \\(n\\). This keeps the individual elements of the menus as simple and intuitive as possible. To elicit the value of the menus we have chosen to use a variant of the BDM auction method proposed by Becker, DeGroot, and Marschak (1964). This auction method consists in asking the subjects the maximum amount they would be willing to pay to acquire a good, then to randomly choose a number; if the number drawn is lower than the value announced by the subject then the subject must buy the good for the amount drawn. This method encourages the subject to reveal the true maximum amount he is willing to pay for a good. Indeed, a subject who does not indicate his true value runs the risk of paying more for a good than he is willing to pay or risks not acquiring the good for an amount lower than what he would have been willing to pay. The method we use differs from the one presented in Becker, DeGroot, and Marschak (1964) because we want to compare menus between them. So we ask subjects for the maximum amount they is willing to pay to exchange one menu for another (we will call this amount willingness-to-change, WTC). To elicit the WTC between two menus we present to subjects one menu on the left of the screen and another on the right. Subjects have to indicate an amount between -$1 and $1 corresponding to the maximum amount they are ready to pay to exchange the menu on the left against the one on the right. If the randomly chosen number is less than the value indicated by the subject, the subject receives the right menu and must pay an amount equal to the number drawn (paying a negative amount means receiving money). If the number drawn at random is strictly higher than the amount indicated by the subject, the subject receives the left menu. In our experiment, subjects indicate the maximum amount they are willing to pay using a slider located between the 2 menus. In order not to induce an anchoring effect, the initial position of the slider is determined randomly for each comparison. This allows us to see that in 85.39% of the cases the subjects have effectively indicated their preference by moving the slider from the place where it was initially placed. As with 6 different items it is possible to build 63 different menus and therefore 1953 different 2-by-2 comparisons, we restricted the comparisons made by the subjects to the ones that seemed the most interesting for us2. These comparisons were chosen to allow reliable estimates of preferences with many observations of comparison of size 1 menus with each other and with size 2 menus; but also to cover a wide range of items and menu sizes. The 35 comparisons are chosen randomly and independently for each subject according to the following rules: 10 comparisons between menus of size 1. The menus of size 1 are chosen randomly but in such a way that each menu appears at least once and that it is possible by 2-by-2 comparisons to reconstruct 1 chain of all menus of size 1. This comparisons is used to estimate preferences over singletons. 12 comparisons between menus of size 1 and size 2. The menus to be compared are drawn at random but we make sure that the menus of size 2 containing the elements 2 and 32 (the extreme lotteries) are compared at least once with the menus of {2} and {32} in order to facilitate the imputation by a utility function of the elements which were not directly compared. This comparisons is used to estimate temptation preferences 3 menus of size 2 between them drawn at random. 3 menus of size 3 with menus of size 2 drawn at random. 1 menu of size 5 drawn at random with 1 menu of size 4 and 1 menu of size 2. menu of sizes 6 with 1 random menu of each other size. Finally, as the subjects have chosen menus and once all the comparisons are done, 5 comparisons among the 35 are drawn at random and a menu for each of the chosen comparisons is selected using the described procedure. The subjects then have to choose in each of these menus one and only one lottery. This lottery is played and the outcome added to the subjects’ payoffs. 3.2.2 Estimations and Models In order to implement the economic models on our data, it is necessary to estimate the preferences of the subjects. In the following sections we present the methods we have chosen. In order to estimate individual preferences on singletons, we use the following methodology: We consider a menu comparison set of size 1. For each comparison we construct 2 equations. For example, if we consider the comparison between a menu A and a menu B we construct the 2 equations: \\(A = B + x\\) \\(B = A - x\\) We assign a value of 0 to one of the menus. We solve each equation for which the right-hand side can be calculated. Each singleton is assigned the average value of the equations for which it is the left-hand member that could be calculated. Repeat step 3 until the desired number of iterations is reached. Each singleton is assigned the average value of the last n iterations (or n an arbitrary number). We normalize the values by subtracting the value of one of the singletons. We tested this methodology on our data and the procedure seem to converge quickly after about 30 iterations the variation in the estimated value is negligible. And the result is independent of the singleton chosen as starting point. This methodology allows us to estimate the preferences over singletons while taking into account the variability in the subjects’ responses. However, this method is based on two assumptions: there exists a preference value for the singletons to be estimated and the comparison of elements is symmetrical. We do not test either of these two hypotheses in our experiment but consider them as valid or at least as reasonable approximations. To estimate the effect of temptation, we use a procedure similar to the one used to estimate preferences over singletons. The only difference is the way we build the equations from a comparison between two menus. As an example, we focus here on comparisons between menus of size 2 and size 1. We use the estimates made on the singletons to identify the preferred item in each menu of size 2. Once this item is identified we compute a theoretical difference with the menu of size 1 by subtracting the estimated value of the preferred item of the menu of size 2 from the one of size 1. We calculate the corrected comparison of preferences that we use to build our 2 equations. For example let us consider the comparison between the menus \\(A = \\{a_1, a_2\\}\\) and \\(B = \\{b\\}\\), and suppose that the estimates of the preferences for the singletons yield \\(hat{u}(\\{a_1\\}) &gt; \\hat{u}(\\{a_2\\})\\). We note \\(wtc_t = \\hat{u}(\\{a_1\\}) - \\hat{u}(\\{b\\})\\). We build the 2 equations: \\(A = B + x - wtc_t\\) \\(B = A - x + wtc_t\\) With these equations we use the same procedure as for the estimation of singletons. The preferences estimated in this way allow us to calculate the value predicted by the expected utility model for each of our 35 menus. In our analysis we will compare the results of 5 different models. These models are grouped in two categories, the statistical models which are the application of statistical methods to our data and the economic models which are implementations of economic theories adapted to our data. The two statistical models are the following: Constant response model. This model consists in calculating for each individual the aggregate average WTC he is willing to pay, over all comparisons between menus of size one and between menus of sizes two and one. This model predicts that the WTC of an individual for any pair of menu items is his average aggregate WTC. This is a dummy model, but it is useful as a lower-bar reference point. It seems reasonable to assume that a model incorporating preferences has to be more efficient than this constant response model. Using this kind of dummy models as a comparison point is a common practice in machine learning. Linear regression. This model consists in estimating a linear regression model for each individual. The explained variable of this regression is the WTC between 2 menus and the explanatory variables are variables indicating the presence of the elements in the compared menus. This type of model is the usual starting point in machine learning, it is relatively simple, not expensive in terms of calculation and can easily predict new values if we have the corresponding explanatory variables, which is our case. The economic models that we have chosen are the following: The expected utility model (EUT). This is the model that corresponds to the standard theory in economics where the value of a menu depends only on the value of the item inside it that will be chosen, therefore on the preferred item that it contains. We have chosen to call it the expected utility model because our menus contain lotteries. The WTC between two menus is calculated as the difference between the preferred items that each menu contains. We have to estimate for each individual the relative value of each item contained in the menus. The Gul and Pesendorfer model (G-P). In this model, we estimate the value of a menu with the following formula: \\[ U(A) = max_{x \\in A}(u(x) + v(x)) - max_{y \\in A}(v(y)) \\] We have to estimate for each individual two preferences for each item present in the menus. and we estimate the WTC as the difference between the estimated values of the two menus. The cumulative temptation model. We estimate the value with the following formula: \\[ U(A) = max_{x \\in A}(u(x) + v(x)) - \\sum_{y \\in A}(v(y)) \\] This model uses the same estimation as the previous one but this time the temptation effect of all the items of a menu is taken into account not only that of a particular item. 3.3 Results Our analysis is based on the assumption of symmetry of the WTC. Indeed, we consider that if an individual is willing to pay x$ to switch from menu A to menu B, this individual will be willing to pay -x$ to switch from menu B to menu A. As we consider this hypothesis to be true, we applied it as a pre-processing on our data so that the left menu is always the larger of the two menus to compare by modifying the WTC multiplying it by -1 when necessary. This modification is intended to make the analysis easier to understand and does not change the results. The starting point for estimating the different economic models presented is the estimation of individual preferences. To estimate the preferences over singletons we use the 10 comparisons of menus of size 1 made for each individual. We iterate on the resulting equation system 500 times and we keep as value for each item the average of the last 50 iterations. Finally as we compute relative preferences, we normalize each value by subtracting the value of the singleton {2}. This method gives us estimates for the 6 possible singletons for 98.32% of our subjects. An error in the programming of the experimental software has wrongly validated strings of singletons for 1.68% of the subjects making our estimation procedure invalid for them, so we have removed these subjects from our study. Since singletons can be seen as lotteries, we can test if subjects have consistent preferences in terms of risks. We consider preferences as consistent in terms of risk if the singleton {N} is the singleton whose estimated utility is maximum then the estimated utility of the singleton {P} is higher than that of the singleton {Q} if \\(N &gt; P &gt; Q\\) or if \\(N &lt; P &lt; Q\\) i.e. single-peaked preferences. Among our subjects we find that 10.27% have consistent, single-peaked preferences. This may seem low and could call into question our method of estimating preferences. However, our estimates are strongly correlated with the subjects’ responses as presented in the figure 3.1. The small number of subjects with single-peak preferences combined with the elements presented in the next chapter concerning the difficulties of estimating individual utility functions leads us not to try to smooth values in our estimates. An erroneous smoothing could be harmful to our analysis. If this does not pose a major problem in the case of the estimation of singletons, we will see that it is on the other hand problematic for the estimation of the temptation effect. Figure 3.1: High correlation between observation and estimation WTC for size 1 menus Using the estimated utilities for the singletons and the 12 comparisons between size 2 and size 1 menus we can estimate the temptation utility of each item for each subject. We iterate again 500 times on the equation system provided by the 12 comparisons and we retain for the estimation of the relative utility of each item the average of the last 50 iterations. To normalize we subtract from all values the estimate for the temptation element \\(2\\). We obtain estimates for each subject, but as expected given our design, we do not have the estimates for each item. The table 3.1 summarizes the percentage of subjects for whom we have no estimate by item. Table 3.1: Share of subjects without estimation by items 2 4 6 8 16 32 0 15.75 19.18 15.75 13.7 0 With 37.67% of the subjects for whom 1 item has no estimate and 13.36% for whom 2 items have no estimate. As these missing estimates are not located on the extreme values, theoretically it would have been easy to impute them by smoothing the estimated values with a utility function. But we have seen with the estimates of the singletons that such a smoothing is not reasonable in practice, as the level of consistency is too low to make this a meaningful exercise. We will therefore keep this value as missing in the rest of the analysis. But missing values do not seem to have an important impact on the predictions of the G-P model. Indeed, by comparing the predictions made on all the comparisons between menus the correlation between prediction and observation is 0.45 on all the available value and 0.47 when we restrict on observation for which we have all item estimated. Since restriction to full estimate item menus don’t seem to have an important impact in the analysis, in the following we willuse all available data. Figure 3.2 shows the distribution of the estimates for each of the items. Figure 3.2: Distribution of the estimate value of item for all subjects We can see that the estimates are of the same order of magnitude across items and across preferences for singletons and for the temptation effect. The estimates for singletons seem slightly lower than for temptation but this does not seem to be a significant difference. There are no elements that appear to be outliers in these estimates. Using these estimates we can calculate for each of our economic models the WTC of each comparison made by our subjects. As a benchmark to judge the quality of the predictions of our economic models we estimate two statistical models, a constant response model and a regression model. To estimate the constant response model, we simply compute the average of the subjects’ responses in terms of WTC for the size 1 menu comparison and for the comparison between size 2 and size 1 menus. The average of these 22 comparisons for each subject is the prediction for any comparison made by this model. The regression model is estimated as follows. For each subject, a linear least square regression model is estimated with the data concerning the size 1 menu comparisons and the size 2 menu comparisons with size 1 menu. The model has the following form: \\[ WTC = \\beta_0 + \\beta_1 L_2 + \\beta_2 L_4 + \\beta_3 L_6 + \\beta_4 L_8 + \\beta_5 L_{16} + \\beta_6 L_{32} + \\beta_7 S_2 + \\beta_8 S_4 + \\beta_9 S_6 + \\beta_{10} S_8 + \\beta_{11} S_{16} \\] Where \\(L_i\\) is an indicator variable for the presence of item \\(i\\) in the largest menu and \\(S_i\\) the same for the presence of \\(i\\) in the smallest menu. Note that our model does not contain the indicator variable \\(S_{32}\\) because it is a linear combination of the other variables given the menu size constraint. The estimates of each of the model parameters for each subject are shown in the figure 3.3. Figure 3.3: Distribution of the coefficent by items for all subjects We can see on the graph that the effect in the different variables of the model are of the same order of magnitude and close to 0. The estimated values are close to the ones estimated for the economic models especially by comparing the indicator variables for the largest menu with the preferences for singletons and the one for the smallest menu with the estimates of the preferences for the temptation. However, it would be premature to interpret the coefficients of the regression as individual preferences for the different items. Indeed our model does not take into account the interaction between the different variables which could be captured in the estimates value of the different coefficients and bias the interpretation. We can however eliminate the hypothesis that subjects evaluate a menu according to the sum of the items that compose it. Indeed in this situation there would be no interaction between the different elements of a menu and we should observe that all the coefficients for the largest menu are higher or equal to 0 and all those for the smallest menu are lower or equal to 0. This is not the case here. As our objective is to use the regression model as a tool for comparison with other models, we will not try to interpret its coefficients at the individual level. We will simply compare the predictions generated by this model with the predictions of other models and the responses of the subjects. Now that we have estimated the different parameters for our 5 models, we can compare their performances using 3 different metrics: Mean Square Error (MSE), which is the mean square difference between the predictions of a model and the observed values. This metric is the default metric in many machine learning applications because of its mathematical form and because it penalizes models with errors that are very far from the observations. Pearson correlation coefficient, which is an indicator of linear co-tendency between two sets of values. As our economic models are estimated from relative utility estimates, we use this indicator to test that a model is at least consistent with the data in terms of trend even if its predictions are biased. Percentage of correct sign estimate: our study concerns preferences between menus, so we expect a model to be able to correctly predict whether an individual will prefer one menu to another or whether he will be indifferent between two menus. For each model we compute the number of times it predicts a WTC of the same sign as the one observed3. In the table 3.2, we present the results of the five models according to the three metrics, calculated on all the comparisons. Table 3.2: Performance of the models, all comparisons model MSE correlation correct sign Linear model 0.31 0.59 0.73 G-P temptation 0.32 0.45 0.54 Constant response 0.33 0.38 0.59 Expected utility 0.36 0.37 0.47 Cumulative temptation 0.46 0.33 0.56 We see that the model that performs best by all metrics is the linear regression model. The constant response model is second in terms of percentage of correct sign and MSE, which tells us that the economic models are globally poor descriptors of the subjects’ behavior. Among the economic models, we see that the best performing model is the G-P model. It is only beaten by the cumulative temptation model for the percentage of correct sign predicted. However, the latter model performs very poorly in terms of MSE and correlation. Finally, if we compare the G-P model with the expected utility model, we see that taking into account the temptation effect represents a marginal improvement in descriptive power. But insofar as these two models perform less well than the constant response model, it seems unwise to use them. The table 3.3 shows the performance of each model according to the type of comparison. Before detailing the results, it should be remembered that the different models were trained using the size 1 menu comparison and the size 2 menu comparison with the size 1 menus. These two categories represents 62.86% of the observations. Table 3.3: Performance of models by comparaison type model 1 vs 1 2 vs 1 other correlation Expected utility 0.82 0.10 0.18 G-P temptation 0.82 0.36 0.18 Cumulative temptation 0.83 0.30 0.14 Linear model 0.86 0.85 0.31 Constant response 0.27 0.48 0.39 MSE Expected utility 0.12 0.49 0.43 G-P temptation 0.12 0.37 0.43 Cumulative temptation 0.12 0.51 0.63 Linear model 0.09 0.11 0.68 Constant response 0.35 0.30 0.34 correct sign Expected utility 0.78 0.36 0.33 G-P temptation 0.78 0.51 0.37 Cumulative temptation 0.78 0.52 0.47 Linear model 0.81 0.83 0.57 Constant response 0.54 0.63 0.60 The first noticeable element in this table is that the different economic models produce the same results for comparisons between menus of size 1. The results for this type of comparison are quite good, they are far superior to those of the constant response model and only slightly inferior to the regression model. On the other hand, if we look at the comparisons of size 2 menus against size 1 menus, the performance of the economic models falls below that of the constant response model. And this remains true for the other types of comparisons. The linear regression model is the best model on the training data but it too performs worse than the constant response model on the new comparison types, it remains superior to the economic model on these data. This may indicate an overlearning problem on the training data. Now if we look at the performance of the economic models we see that the G-P model performs better than the EUT model. It seems that integrating temptation in the evaluation of the comparison between size 2 and size 1 menus allows to improve the predictions according to our 3 metrics. But this effect does not seem to have any impact for the other types of comparisons. This may indicate that the improvements for the comparison between size 2 and size 1 menus is due to an overlearning phenomenon. It may also be a sign that the G-P model does not use the right functional form. Indeed, alternatives to the G-P model like Noor and Takeoka (2015) postulate that the effect of temptation is not linear. This could be a way to improve the performance of the model for other types of comparisons but such a model would also be less efficient than a constant response model for comparisons between menus of sizes 2 and 1, which therefore does not seem to be a promising direction for improvement. Finally, the cumulative temptation model is less efficient than the G-P model except in predicting the sign of the WTCs, but it is still inferior to the constant response model on this metric too. We have just seen that economic models are poor descriptors of subjects’ behavior when dealing with menus of more than one option. In the figure 3.4 we show that these models have in common to predict that subjects are indifferent between two menus much more frequently than what we observe. And that this is also their main difference with the linear regression model which has better performances. Figure 3.4: Distribution of the WTC value predict by models If the economic models often predict the value 0 – i.e., indifference between the two compared menus – this is because they evaluate the menus according to the preferred item they contain. In the case of the expected utility model this implies that all menus that share the same preferred item will have the same estimated value. In the case of the G-P model this phenomenon is attenuated by the effect of temptation of another menu item but remains important and the menus that share their preferred item will have close values. However, we observe on the comparison of the menus that subjects are rarely indifferent between two menus. This seems to contradict the fact that subjects evaluate menus based on a particular item. 3.4 Discussion In this chapter we have proposed an experiment that compares the descriptive quality of the model in Gul and Pesendorfer (2001) with other economic and statistical models. Our test does not aim at testing the existence of a behavior predicted by the theory as the rest of the experimental literature on the subject but at testing the theoretical framework proposed to rationalize this behavior. Our experiment thus allows us to highlight that the theoretical approach proposed by G-P does not adequately account for the observed behavior of the subjects. We show in effect that a dummy constant response model produces predictions as close to the observations as G-P’s model in terms of precision, tendency and preference between menus. Our experiment globally questions the menu choice approach proposed by Kreps (1979) and followed by G-P and the temptation models presented in the review of Lipman, Pesendorfer, and others (2013). These models, although an improvement over the expected utility model, are poor descriptors of our observations. Their specific item comparison-based approaches underestimate the difference between two menus reported by our subjects, notably by predicting that subjects will be indifferent between options over which subjects are not indifferent. In this respect, machine learning methods such as simple linear regressions – that take into account all elements of a menu and not just some preferred ones – are at least better descriptors of our data than economic models. We show in effect that a simple model trained at the individual level offers better predictions in terms of trend predictions and preferences between menus than the economic models and the dummy constant response model. Nevertheless, it should be noted that our analysis, like the menu choice framework, is based on expected utility theory. And although we used the most robust estimation methods possible, it is possible that our results are biased by a discrepancy between the observed behavior of the subjects and that predicted by expected utility theory. Part of this issue will be studied in the next chapter. We believe that in order to propose models with better descriptive power it would be useful to have more information on the structure of individual errors. This would allow us to improve the descriptive performance of risk preference models as well as models derived from them such as the Gul-Pesendorfer model. References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
